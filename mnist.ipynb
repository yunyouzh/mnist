{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1000\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download and import mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(root='./',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "test_data = torchvision.datasets.MNIST(root='./',train=False,transform=torchvision.transforms.ToTensor())\n",
    "train_loader = Data.DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
    "test_x = Variable(test_data.test_data.view(-1, 28*28)).type(torch.FloatTensor)\n",
    "test_y = test_data.test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNets(nn.Module):\n",
    "    def __init__(self,nlist):\n",
    "        super(FCNets,self).__init__()\n",
    "        if len(nlist) < 2:\n",
    "            print('error:not enough layers')\n",
    "        else:\n",
    "            self.fc = nn.Sequential()\n",
    "            for n in range(len(nlist)-1):\n",
    "                self.fc.add_module('linear' + str(n+1), nn.Linear(in_features=nlist[n], out_features=nlist[n+1]))\n",
    "                self.fc.add_module('relu' + str(n+1), nn.ReLU())\n",
    "            #self.fc.add_module('softmax', nn.Softmax())\n",
    "    def forward(self,x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Neural Net instance and optimizer, loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNets(\n",
      "  (fc): Sequential(\n",
      "    (linear1): Linear(in_features=784, out_features=32)\n",
      "    (relu1): ReLU()\n",
      "    (linear2): Linear(in_features=32, out_features=10)\n",
      "    (relu2): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "fc = FCNets([28*28,32,10])\n",
    "print(fc)\n",
    "optimizer = torch.optim.SGD(params=fc.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 train loss:2.1022 test accuracy is:0.464\n",
      "Epoch: 5 train loss:0.5180 test accuracy is:0.855\n",
      "Epoch: 10 train loss:0.7293 test accuracy is:0.887\n",
      "Epoch: 15 train loss:0.1292 test accuracy is:0.900\n",
      "Epoch: 20 train loss:0.3315 test accuracy is:0.909\n",
      "Epoch: 25 train loss:0.1575 test accuracy is:0.913\n",
      "Epoch: 30 train loss:0.0921 test accuracy is:0.917\n",
      "Epoch: 35 train loss:0.1337 test accuracy is:0.921\n",
      "Epoch: 40 train loss:0.3854 test accuracy is:0.917\n",
      "Epoch: 45 train loss:0.0991 test accuracy is:0.922\n",
      "Epoch: 50 train loss:0.1218 test accuracy is:0.921\n",
      "Epoch: 55 train loss:0.0917 test accuracy is:0.923\n",
      "Epoch: 60 train loss:0.0623 test accuracy is:0.926\n",
      "Epoch: 65 train loss:0.1326 test accuracy is:0.924\n",
      "Epoch: 70 train loss:0.0731 test accuracy is:0.927\n",
      "Epoch: 75 train loss:0.3682 test accuracy is:0.922\n",
      "Epoch: 80 train loss:0.1956 test accuracy is:0.930\n",
      "Epoch: 85 train loss:0.0486 test accuracy is:0.926\n",
      "Epoch: 90 train loss:0.0683 test accuracy is:0.931\n",
      "Epoch: 95 train loss:0.2008 test accuracy is:0.929\n",
      "Epoch: 100 train loss:0.0451 test accuracy is:0.932\n",
      "Epoch: 105 train loss:0.1100 test accuracy is:0.936\n",
      "Epoch: 110 train loss:0.1312 test accuracy is:0.935\n",
      "Epoch: 115 train loss:0.4883 test accuracy is:0.932\n",
      "Epoch: 120 train loss:0.0910 test accuracy is:0.936\n",
      "Epoch: 125 train loss:0.2054 test accuracy is:0.933\n",
      "Epoch: 130 train loss:0.0471 test accuracy is:0.936\n",
      "Epoch: 135 train loss:0.0496 test accuracy is:0.933\n",
      "Epoch: 140 train loss:0.0926 test accuracy is:0.934\n",
      "Epoch: 145 train loss:0.3210 test accuracy is:0.936\n",
      "Epoch: 150 train loss:0.1375 test accuracy is:0.941\n",
      "Epoch: 155 train loss:0.0234 test accuracy is:0.938\n",
      "Epoch: 160 train loss:0.0264 test accuracy is:0.943\n",
      "Epoch: 165 train loss:0.0372 test accuracy is:0.945\n",
      "Epoch: 170 train loss:0.0302 test accuracy is:0.945\n",
      "Epoch: 175 train loss:0.4571 test accuracy is:0.945\n",
      "Epoch: 180 train loss:0.1209 test accuracy is:0.943\n",
      "Epoch: 185 train loss:0.0414 test accuracy is:0.945\n",
      "Epoch: 190 train loss:0.0771 test accuracy is:0.947\n",
      "Epoch: 195 train loss:0.0306 test accuracy is:0.945\n",
      "Epoch: 200 train loss:0.0089 test accuracy is:0.946\n",
      "Epoch: 205 train loss:0.2843 test accuracy is:0.947\n",
      "Epoch: 210 train loss:0.0781 test accuracy is:0.949\n",
      "Epoch: 215 train loss:0.2368 test accuracy is:0.950\n",
      "Epoch: 220 train loss:0.0309 test accuracy is:0.952\n",
      "Epoch: 225 train loss:0.1313 test accuracy is:0.953\n",
      "Epoch: 230 train loss:0.1070 test accuracy is:0.955\n",
      "Epoch: 235 train loss:0.0880 test accuracy is:0.953\n",
      "Epoch: 240 train loss:0.1053 test accuracy is:0.955\n",
      "Epoch: 245 train loss:0.0358 test accuracy is:0.954\n",
      "Epoch: 250 train loss:0.0119 test accuracy is:0.955\n",
      "Epoch: 255 train loss:0.0812 test accuracy is:0.955\n",
      "Epoch: 260 train loss:0.0310 test accuracy is:0.955\n",
      "Epoch: 265 train loss:0.0414 test accuracy is:0.954\n",
      "Epoch: 270 train loss:0.0253 test accuracy is:0.957\n",
      "Epoch: 275 train loss:0.1089 test accuracy is:0.954\n",
      "Epoch: 280 train loss:0.0442 test accuracy is:0.959\n",
      "Epoch: 285 train loss:0.0310 test accuracy is:0.961\n",
      "Epoch: 290 train loss:0.0636 test accuracy is:0.959\n",
      "Epoch: 295 train loss:0.0795 test accuracy is:0.959\n",
      "Epoch: 300 train loss:0.0130 test accuracy is:0.963\n",
      "Epoch: 305 train loss:0.0849 test accuracy is:0.961\n",
      "Epoch: 310 train loss:0.0246 test accuracy is:0.960\n",
      "Epoch: 315 train loss:0.0273 test accuracy is:0.966\n",
      "Epoch: 320 train loss:0.1579 test accuracy is:0.960\n",
      "Epoch: 325 train loss:0.0075 test accuracy is:0.964\n",
      "Epoch: 330 train loss:0.1349 test accuracy is:0.966\n",
      "Epoch: 335 train loss:0.0024 test accuracy is:0.963\n",
      "Epoch: 340 train loss:0.0184 test accuracy is:0.965\n",
      "Epoch: 345 train loss:0.1910 test accuracy is:0.968\n",
      "Epoch: 350 train loss:0.0279 test accuracy is:0.965\n",
      "Epoch: 355 train loss:0.0374 test accuracy is:0.969\n",
      "Epoch: 360 train loss:0.0297 test accuracy is:0.966\n",
      "Epoch: 365 train loss:0.0018 test accuracy is:0.970\n",
      "Epoch: 370 train loss:0.1256 test accuracy is:0.972\n",
      "Epoch: 375 train loss:0.0148 test accuracy is:0.968\n",
      "Epoch: 380 train loss:0.0075 test accuracy is:0.970\n",
      "Epoch: 385 train loss:0.1088 test accuracy is:0.970\n",
      "Epoch: 390 train loss:0.0172 test accuracy is:0.972\n",
      "Epoch: 395 train loss:0.0101 test accuracy is:0.971\n",
      "Epoch: 400 train loss:0.0485 test accuracy is:0.970\n",
      "Epoch: 405 train loss:0.0259 test accuracy is:0.971\n",
      "Epoch: 410 train loss:0.0413 test accuracy is:0.971\n",
      "Epoch: 415 train loss:0.0262 test accuracy is:0.971\n",
      "Epoch: 420 train loss:0.0242 test accuracy is:0.971\n",
      "Epoch: 425 train loss:0.0243 test accuracy is:0.972\n",
      "Epoch: 430 train loss:0.0070 test accuracy is:0.973\n",
      "Epoch: 435 train loss:0.0092 test accuracy is:0.972\n",
      "Epoch: 440 train loss:0.0081 test accuracy is:0.973\n",
      "Epoch: 445 train loss:0.0233 test accuracy is:0.973\n",
      "Epoch: 450 train loss:0.0337 test accuracy is:0.973\n",
      "Epoch: 455 train loss:0.0158 test accuracy is:0.974\n",
      "Epoch: 460 train loss:0.0261 test accuracy is:0.976\n",
      "Epoch: 465 train loss:0.1048 test accuracy is:0.976\n",
      "Epoch: 470 train loss:0.0151 test accuracy is:0.974\n",
      "Epoch: 475 train loss:0.0087 test accuracy is:0.975\n",
      "Epoch: 480 train loss:0.0437 test accuracy is:0.975\n",
      "Epoch: 485 train loss:0.0827 test accuracy is:0.974\n",
      "Epoch: 490 train loss:0.0041 test accuracy is:0.975\n",
      "Epoch: 495 train loss:0.0565 test accuracy is:0.976\n",
      "Epoch: 500 train loss:0.0379 test accuracy is:0.978\n",
      "Epoch: 505 train loss:0.0190 test accuracy is:0.976\n",
      "Epoch: 510 train loss:0.0482 test accuracy is:0.976\n",
      "Epoch: 515 train loss:0.0377 test accuracy is:0.976\n",
      "Epoch: 520 train loss:0.0159 test accuracy is:0.978\n",
      "Epoch: 525 train loss:0.0310 test accuracy is:0.976\n",
      "Epoch: 530 train loss:0.0105 test accuracy is:0.978\n",
      "Epoch: 535 train loss:0.1053 test accuracy is:0.978\n",
      "Epoch: 540 train loss:0.0111 test accuracy is:0.976\n",
      "Epoch: 545 train loss:0.0071 test accuracy is:0.978\n",
      "Epoch: 550 train loss:0.0316 test accuracy is:0.978\n",
      "Epoch: 555 train loss:0.0092 test accuracy is:0.977\n",
      "Epoch: 560 train loss:0.0387 test accuracy is:0.979\n",
      "Epoch: 565 train loss:0.0244 test accuracy is:0.980\n",
      "Epoch: 570 train loss:0.0153 test accuracy is:0.979\n",
      "Epoch: 575 train loss:0.0475 test accuracy is:0.979\n",
      "Epoch: 580 train loss:0.0087 test accuracy is:0.978\n",
      "Epoch: 585 train loss:0.0016 test accuracy is:0.979\n",
      "Epoch: 590 train loss:0.0251 test accuracy is:0.978\n",
      "Epoch: 595 train loss:0.0037 test accuracy is:0.981\n",
      "Epoch: 600 train loss:0.0031 test accuracy is:0.978\n",
      "Epoch: 605 train loss:0.0242 test accuracy is:0.981\n",
      "Epoch: 610 train loss:0.0232 test accuracy is:0.980\n",
      "Epoch: 615 train loss:0.0539 test accuracy is:0.980\n",
      "Epoch: 620 train loss:0.0044 test accuracy is:0.979\n",
      "Epoch: 625 train loss:0.0444 test accuracy is:0.982\n",
      "Epoch: 630 train loss:0.0135 test accuracy is:0.981\n",
      "Epoch: 635 train loss:0.0224 test accuracy is:0.980\n",
      "Epoch: 640 train loss:0.0123 test accuracy is:0.982\n",
      "Epoch: 645 train loss:0.0065 test accuracy is:0.982\n",
      "Epoch: 650 train loss:0.0615 test accuracy is:0.981\n",
      "Epoch: 655 train loss:0.0150 test accuracy is:0.981\n",
      "Epoch: 660 train loss:0.0039 test accuracy is:0.982\n",
      "Epoch: 665 train loss:0.0098 test accuracy is:0.983\n",
      "Epoch: 670 train loss:0.0019 test accuracy is:0.982\n",
      "Epoch: 675 train loss:0.0574 test accuracy is:0.982\n",
      "Epoch: 680 train loss:0.0072 test accuracy is:0.982\n",
      "Epoch: 685 train loss:0.0151 test accuracy is:0.982\n",
      "Epoch: 690 train loss:0.0225 test accuracy is:0.982\n",
      "Epoch: 695 train loss:0.0225 test accuracy is:0.983\n",
      "Epoch: 700 train loss:0.0025 test accuracy is:0.982\n",
      "Epoch: 705 train loss:0.0129 test accuracy is:0.982\n",
      "Epoch: 710 train loss:0.0113 test accuracy is:0.983\n",
      "Epoch: 715 train loss:0.0025 test accuracy is:0.983\n",
      "Epoch: 720 train loss:0.0654 test accuracy is:0.983\n",
      "Epoch: 725 train loss:0.0179 test accuracy is:0.984\n",
      "Epoch: 730 train loss:0.0158 test accuracy is:0.984\n",
      "Epoch: 735 train loss:0.0016 test accuracy is:0.983\n",
      "Epoch: 740 train loss:0.0028 test accuracy is:0.985\n",
      "Epoch: 745 train loss:0.0153 test accuracy is:0.985\n",
      "Epoch: 750 train loss:0.0061 test accuracy is:0.984\n",
      "Epoch: 755 train loss:0.0104 test accuracy is:0.984\n",
      "Epoch: 760 train loss:0.0180 test accuracy is:0.984\n",
      "Epoch: 765 train loss:0.0086 test accuracy is:0.984\n",
      "Epoch: 770 train loss:0.0023 test accuracy is:0.984\n",
      "Epoch: 775 train loss:0.0057 test accuracy is:0.984\n",
      "Epoch: 780 train loss:0.0158 test accuracy is:0.987\n",
      "Epoch: 785 train loss:0.0025 test accuracy is:0.984\n",
      "Epoch: 790 train loss:0.0010 test accuracy is:0.985\n",
      "Epoch: 795 train loss:0.0056 test accuracy is:0.985\n",
      "Epoch: 800 train loss:0.0003 test accuracy is:0.985\n",
      "Epoch: 805 train loss:0.0085 test accuracy is:0.985\n",
      "Epoch: 810 train loss:0.0012 test accuracy is:0.986\n",
      "Epoch: 815 train loss:0.0037 test accuracy is:0.986\n",
      "Epoch: 820 train loss:0.0011 test accuracy is:0.986\n",
      "Epoch: 825 train loss:0.0052 test accuracy is:0.985\n",
      "Epoch: 830 train loss:0.0275 test accuracy is:0.986\n",
      "Epoch: 835 train loss:0.0027 test accuracy is:0.986\n",
      "Epoch: 840 train loss:0.0129 test accuracy is:0.985\n",
      "Epoch: 845 train loss:0.0079 test accuracy is:0.986\n",
      "Epoch: 850 train loss:0.0028 test accuracy is:0.986\n",
      "Epoch: 855 train loss:0.0030 test accuracy is:0.986\n",
      "Epoch: 860 train loss:0.0202 test accuracy is:0.986\n",
      "Epoch: 865 train loss:0.0146 test accuracy is:0.987\n",
      "Epoch: 870 train loss:0.0029 test accuracy is:0.986\n",
      "Epoch: 875 train loss:0.0026 test accuracy is:0.987\n",
      "Epoch: 880 train loss:0.0073 test accuracy is:0.986\n",
      "Epoch: 885 train loss:0.0078 test accuracy is:0.986\n",
      "Epoch: 890 train loss:0.0132 test accuracy is:0.986\n",
      "Epoch: 895 train loss:0.0073 test accuracy is:0.987\n",
      "Epoch: 900 train loss:0.0059 test accuracy is:0.987\n",
      "Epoch: 905 train loss:0.0070 test accuracy is:0.987\n",
      "Epoch: 910 train loss:0.0128 test accuracy is:0.987\n",
      "Epoch: 915 train loss:0.0031 test accuracy is:0.987\n",
      "Epoch: 920 train loss:0.0131 test accuracy is:0.987\n",
      "Epoch: 925 train loss:0.0222 test accuracy is:0.987\n",
      "Epoch: 930 train loss:0.0006 test accuracy is:0.988\n",
      "Epoch: 935 train loss:0.0056 test accuracy is:0.987\n",
      "Epoch: 940 train loss:0.0046 test accuracy is:0.987\n",
      "Epoch: 945 train loss:0.0286 test accuracy is:0.987\n",
      "Epoch: 950 train loss:0.0051 test accuracy is:0.987\n",
      "Epoch: 955 train loss:0.0176 test accuracy is:0.988\n",
      "Epoch: 960 train loss:0.0063 test accuracy is:0.988\n",
      "Epoch: 965 train loss:0.0069 test accuracy is:0.986\n",
      "Epoch: 970 train loss:0.0031 test accuracy is:0.987\n",
      "Epoch: 975 train loss:0.0038 test accuracy is:0.987\n",
      "Epoch: 980 train loss:0.0042 test accuracy is:0.987\n",
      "Epoch: 985 train loss:0.0059 test accuracy is:0.988\n",
      "Epoch: 990 train loss:0.0105 test accuracy is:0.987\n",
      "Epoch: 995 train loss:0.0096 test accuracy is:0.987\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        x = x.view(-1,28*28)\n",
    "        bx = Variable(x)\n",
    "        by = Variable(y)\n",
    "        output = fc(bx)\n",
    "        loss = loss_func(output, by)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%5 == 0:\n",
    "        y_predict = torch.max(fc(test_x),1)[1].data\n",
    "        accuracy = sum(y_predict == test_y)/len(test_y)\n",
    "        print('Epoch:',epoch,'train loss:%.4f' %loss.data[0],'test accuracy is:%.3f' %accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if neural nets size is 784 10\n",
    "with lr = 0.01 \n",
    "achieve accuracy of 92%\n",
    "if neural nets size is 784 32 10\n",
    "with lr = 0.01 epoch=1000\n",
    "achieve accuracy of 98.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([32, 784])\n",
      "<class 'torch.FloatTensor'> torch.Size([32])\n",
      "<class 'torch.FloatTensor'> torch.Size([10, 32])\n",
      "<class 'torch.FloatTensor'> torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in fc.parameters():\n",
    "    print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunyou/anaconda3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type FCNets. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(fc,'fc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
